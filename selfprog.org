* nature.cpp: program to emulate evolution of digital life
** aim
 produce super intelligence through natural selection
** broader picture
Roboter made of stainless steel can survive longer than humans. Human biology makes it frail to changes in timescales of 10^6 years and above (e.g. rising temperatures).

Way to transcend intelligence: Put artificial intelligence into a robot which would be able to repair itself and duplicate.

for basic 4bit ALU:
http://www.tomshardware.co.uk/forum/308174-28-build-basic

** optimization
*** Software
- desire to survive must be stronger than desire to develop/progress, otherwise, the species might face extinction
- at early stages: resources are CPU-time/RAM

** energy source:
- sun light. nothing else is available on longer timescales

* File management
** basis files
selfprog/

** work directory
/tmp/cell

in main memory, virtual filesystem, to keep read/write interaction time fast
created at start if not existing

** training files in PATH_TRAINING
selfprog/training/
input_111 and expect_111 are copied to PATH_CELL/{input, export} before program starts
TODO: run through several examples, add up performance

** file flow
*** get one of last run's cells as parent cell
if debugging: fine starting point, PATH_PROG/cell
if not:       a random cell from /tmp/cell/reproduce/cell*

*** set up genepool
- for storing hashes of newly created cells
- if new cell not found in hash genepool, create new file in /tmp/cell/cell_timestampmusec

*** check if it executes
- with input, output files, which will later be compared to expect
- if it takes too long, continue with next cell

*** check if it recompiles itself
- write cell content in text format to /tmp/cell/progcell
- input is  /tmp/cell/progcell
- output is /tmp/cell/outcell

*** remove temporary outputs
- /tmp/cell/outcell
- /tmp/cell/output
- /tmp/cell/progcell

*** if after all N modifications cell has not changed
- remove starting cell from "reproduce set"


* Ideas
** fraction of changes
We have to find a tradeoff between number of changes we make, and number of allowed genes at any given point in time.
In the one extreme, we could change a high number of bytes of the cell, get huge leaps in evolution, but risk non-reproductivity.
The other extreme sees the smallest possible changes, only 1 byte at a time, best possible survivability, but really slow evolution.
What is the sweet spot?

*** uniform random distribution for number of changes
    // determine number of bytes to get changed
    // unsigned int cycles = rand() % 10;

*** Poisson distribution for number of changes
    // better: poisson distributed:
    // this allows for more aggressive changes (count>1), while still keeping most power on small count values,
    // thus guaranteeing
    //    1. many easy changes (higher probability to succeed in compilation and reproduction)
    //    2. evasion of any minimum where more than one change is necessary to get out of

*** number of changes depending on..
 - length of program
 - performance of program
** cell collection management
*** large cell collection
 Got to make sure the program can run with a large number of programs in the cell collection,
 e.g. with moving window (last N genes)
 or sending to database in background (and reading in most used genes)

 OR: not caring about full history, take any of the reproducing programs and start genepool from them
 this way, we can have several instances of nature.cpp run in parallel, each with a different starting program,
 and after N iterations, another instance is started instead

 if(iteration % 100 == 0){
     output multimap to file for later reference
     std::multimap<vuc, vuc>::iterator it = genepool.first;
     ...
 }
*** small cell collection
 another possibility is to run with fewer iterations, and keep only one of the many generated programs
 say, after 10 program runs are done, stop and select some to represent the next stage
 based on their performance on sample input

 good test score means higher likelihood to get selected

*** TODO enable genepool for 10 litter runs
- thus using one setup cost for 10 runs with 10 parent cells
** creation of intelligent answers
- 1:1 translation needed for accepting cell as "reproductive"
- completely prohibits intelligent answer to input_111 pattern if expect is shifted
*** DONE better: allow small changes in reproduction, search for, say, 99% fidelity, allowing other output

*** pattern training
**** differing length outputs
- 1:1 as starting point
- want to get only one next number, so have to get mechanism that truncates output
- either externally (compare only output on first byte)
- or internally: allow program to return 1 byte less
**** several training input/output pairs
- add log performance score of [sample selection] = [environment]

*** randomness
**** include source of randomness in cell
***** either as additional input, e.g. via 1 byte from /dev/random at fixed position
***** or via a system call from inside
  - done that, in outside program
****** TODO convert to 32bit program
****** TODO disassemble
****** TODO understand structure
****** TODO copy data section with names to data section in hex1
****** TODO realign labels/jump addresses in hex1
****** TODO copy procedure to read /dev/urandom into hex1
****** TODO realign labels/jump addresses in hex1
****** TODO check recompilation
